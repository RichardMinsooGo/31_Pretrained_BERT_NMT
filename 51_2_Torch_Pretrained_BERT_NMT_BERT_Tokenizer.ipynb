{"cells":[{"cell_type":"markdown","source":["Last test : 2021-01-30  \n","한국어 설명 : https://wikidocs.net/159246  \n","English Explanation : https://wikidocs.net/160289  \n","Github : https://github.com/RichardMinsooGo/51_Pretrained_BERT_NMT"],"metadata":{"id":"mBP5IObSvkt7"}},{"cell_type":"markdown","source":["We wil use pytorch_pretrained_bert at this notebook"],"metadata":{"id":"Ecj68gnpo-zd"}},{"cell_type":"code","source":["!pip install pytorch_pretrained_bert\n","\n","from IPython.display import clear_output \n","clear_output()"],"metadata":{"id":"KYa0HIx6pDtF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Define the library that we will use. Then check whether GPU is selected.\n"],"metadata":{"id":"3oZlsQkypRWk"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils import data\n","from pytorch_pretrained_bert import BertTokenizer, BertModel, BertForMaskedLM, BertForQuestionAnswering, BertForPreTraining\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_glt0vUgpir0","executionInfo":{"status":"ok","timestamp":1643529081772,"user_tz":-540,"elapsed":9,"user":{"displayName":"Richard Minsoo Go","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09628967547080180869"}},"outputId":"bb40ab2f-4895-4db2-b5a5-5a2fc98eea5e"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["cuda\n"]}]},{"cell_type":"markdown","source":["### 1. Data Load \n","This step is not used, we will define Input and Output at this note book.\n","\n","### 2. Build Input text, Output Text \n","Input/Output Data is defined."],"metadata":{"id":"RFp5NLY6rEG1"}},{"cell_type":"code","source":["input_text  = \"[CLS] I want to buy the new Apple M1 Pro MacBook pro [SEP] \"\n","target_text = \"Je veux acheter le nouveau MacBook Pro Apple M1 Pro\""],"metadata":{"id":"Sd22B8cxrE00"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Load pretrained BERT Model\n","Load the predefined BERT model and check whether the input/output data is correctly created.  \n","In this article, the length of the input and output sentences is longer, and since tokens are divided into several tokens  when tokening is executed including French, the length of the input/output sequence is defined as 30."],"metadata":{"id":"bcXB09jjtGjk"}},{"cell_type":"code","source":["modelpath = \"bert-base-uncased\"\n","\n","# Load pre-trained model tokenizer (vocabulary)\n","model = BertForMaskedLM.from_pretrained(modelpath)\n","model = model.to(device)\n","\n","n_seq_length = 30\n","\n","print(\"input_text       :\", input_text)\n","print(\"target_text      :\", target_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AmogQcqqsxR3","executionInfo":{"status":"ok","timestamp":1643529092077,"user_tz":-540,"elapsed":10312,"user":{"displayName":"Richard Minsoo Go","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09628967547080180869"}},"outputId":"9dba502a-b553-4688-ecb6-ee6e81137314"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["input_text       : [CLS] I want to buy the new Apple M1 Pro MacBook pro [SEP] \n","target_text      : Je veux acheter le nouveau MacBook Pro Apple M1 Pro\n"]}]},{"cell_type":"markdown","source":["### 3. Preprocess \n","When using the BERT tokenizer, there is no need to specify it(pre-process) separately because it has a pre-processing function. However, from the next example, we will include the preprocessing step again."],"metadata":{"id":"FQf5Nb9vym2-"}},{"cell_type":"markdown","source":["### 4. Build Vocabulary\n","In the case of BertTokenizer, there is no need to create a dedicated vocabulary. It has its own built-in vocabulary, so you only need to define a tokenizer."],"metadata":{"id":"wdj99F4ay6UM"}},{"cell_type":"code","source":["tokenizer = BertTokenizer.from_pretrained(modelpath)"],"metadata":{"id":"DRy_ADWLy9Dk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### 5. Tokenize "],"metadata":{"id":"5Vbyn8CX3WsT"}},{"cell_type":"code","source":["tokenized_inp_text = tokenizer.tokenize(input_text)\n","tokenized_trg_text = tokenizer.tokenize(target_text)\n","\n","len_input_text = len(tokenized_inp_text)\n","print(\"len_input_text   :\", len_input_text)\n","\n","print(\"tokenized input  :\", tokenized_inp_text)\n","print(\"tokenized target :\", tokenized_trg_text)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bwOjLAGI1F8k","executionInfo":{"status":"ok","timestamp":1643529092513,"user_tz":-540,"elapsed":7,"user":{"displayName":"Richard Minsoo Go","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09628967547080180869"}},"outputId":"2ebfd026-cff4-4124-a7dd-03c209c484dd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["len_input_text   : 14\n","tokenized input  : ['[CLS]', 'i', 'want', 'to', 'buy', 'the', 'new', 'apple', 'm1', 'pro', 'mac', '##book', 'pro', '[SEP]']\n","tokenized target : ['je', 've', '##ux', 'ache', '##ter', 'le', 'nouveau', 'mac', '##book', 'pro', 'apple', 'm1', 'pro']\n"]}]},{"cell_type":"markdown","source":["### 6. Data Processing\n","In this article, \"6. Data Processing\" and \"7. Convert tokens to indexes\" are done simultaneously. \n","\n","### 7. Convert tokens to indexes\n","As previously explained, this process is not in an exact order. The part to focus on in this process is to check whether the form of the input/output token is properly formed."],"metadata":{"id":"ulGGdiGD3qYL"}},{"cell_type":"code","source":["# Processing for model\n","for _ in range(n_seq_length-len(tokenized_inp_text)):\n","    tokenized_inp_text.append('[MASK]')\n","    \n","indexed_inp_tokens = tokenizer.convert_tokens_to_ids(tokenized_inp_text)\n","\n","# use -1 or 0 only for pytorch_pretrained_bert\n","pad_idx = -1  \n","converted_trg_inds = []\n","converted_trg_inds = [pad_idx] * len_input_text\n","indexed_trg_tokens = tokenizer.convert_tokens_to_ids(tokenized_trg_text)\n","tmp_trg_tensors    = torch.tensor([indexed_trg_tokens])\n","converted_trg_inds += tmp_trg_tensors[0].tolist()\n","converted_trg_inds.append(tokenizer.convert_tokens_to_ids(['[SEP]'])[0])\n","\n","for _ in range(n_seq_length-len(converted_trg_inds)):\n","    converted_trg_inds.append(pad_idx)\n","\n","print(\"Input (Tokenized and indexed)  :\\n\", indexed_inp_tokens)\n","print(\"Output (Tokenized and indexed) :\\n\", converted_trg_inds)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Tr2ta5a83J7M","executionInfo":{"status":"ok","timestamp":1643529092513,"user_tz":-540,"elapsed":6,"user":{"displayName":"Richard Minsoo Go","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09628967547080180869"}},"outputId":"35d9ca15-53c3-4d62-d930-2d5157dc35e3"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Input (Tokenized and indexed)  :\n"," [101, 1045, 2215, 2000, 4965, 1996, 2047, 6207, 23290, 4013, 6097, 8654, 4013, 102, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103]\n","Output (Tokenized and indexed) :\n"," [-1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, -1, 15333, 2310, 5602, 12336, 3334, 3393, 25272, 6097, 8654, 4013, 6207, 23290, 4013, 102, -1, -1]\n"]}]},{"cell_type":"markdown","source":["### 8. Convert indexes to tensors  \n","Convert the index created in Step 7 to tensors.\n","Keep in mind that in deep learning, batch + tensors are given as input."],"metadata":{"id":"lBfCTXu78qxS"}},{"cell_type":"code","source":["tensors_src = torch.tensor([indexed_inp_tokens]).to(device)\n","tensors_trg = torch.tensor([converted_trg_inds]).to(device)\n","\n","print(tensors_src)\n","print(tensors_trg)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-8sRuyTa8pf7","executionInfo":{"status":"ok","timestamp":1643529092513,"user_tz":-540,"elapsed":4,"user":{"displayName":"Richard Minsoo Go","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09628967547080180869"}},"outputId":"96d23df9-7231-46b0-8cb8-9188ffe1bc51"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([[  101,  1045,  2215,  2000,  4965,  1996,  2047,  6207, 23290,  4013,\n","          6097,  8654,  4013,   102,   103,   103,   103,   103,   103,   103,\n","           103,   103,   103,   103,   103,   103,   103,   103,   103,   103]],\n","       device='cuda:0')\n","tensor([[   -1,    -1,    -1,    -1,    -1,    -1,    -1,    -1,    -1,    -1,\n","            -1,    -1,    -1,    -1, 15333,  2310,  5602, 12336,  3334,  3393,\n","         25272,  6097,  8654,  4013,  6207, 23290,  4013,   102,    -1,    -1]],\n","       device='cuda:0')\n"]}]},{"cell_type":"markdown","source":["### Others are normal training process"],"metadata":{"id":"08v0BokAmFd4"}},{"cell_type":"code","source":["# optimizer = torch.optim.Adam(model.parameters(), lr=5e-7)\n","# optimizer = torch.optim.SGD(model.parameters(), lr = 5e-5, momentum=0.9)\n","optimizer = torch.optim.Adamax(model.parameters(), lr = 5e-5)\n","\n","num_epochs = 300\n","\n","model.train()\n","for i in range(num_epochs):\n","    loss = model(tensors_src, masked_lm_labels=tensors_trg)\n","    eveloss = loss.mean().item()\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    if (i+1)%10 == 0:\n","        print(\"step \"+ str(i+1) + \" : \" + str(eveloss))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hm-3siNo9M5D","executionInfo":{"status":"ok","timestamp":1643529111698,"user_tz":-540,"elapsed":19189,"user":{"displayName":"Richard Minsoo Go","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09628967547080180869"}},"outputId":"6b1b5f6d-66fd-43ef-95f4-fadc29ad2d1b"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["step 10 : 3.771027088165283\n","step 20 : 2.700327157974243\n","step 30 : 1.988046646118164\n","step 40 : 1.4163614511489868\n","step 50 : 1.3190759420394897\n","step 60 : 0.6748390793800354\n","step 70 : 0.359968364238739\n","step 80 : 0.33379030227661133\n","step 90 : 0.21821965277194977\n","step 100 : 0.04551782086491585\n","step 110 : 0.07059331238269806\n","step 120 : 0.14557014405727386\n","step 130 : 0.09280121326446533\n","step 140 : 0.02755594253540039\n","step 150 : 0.009662961587309837\n","step 160 : 0.011001522652804852\n","step 170 : 0.024392014369368553\n","step 180 : 0.011023713275790215\n","step 190 : 0.018864227458834648\n","step 200 : 0.003558436641469598\n","step 210 : 0.020779123529791832\n","step 220 : 0.020972367376089096\n","step 230 : 0.004028483293950558\n","step 240 : 0.014759846031665802\n","step 250 : 0.012583794072270393\n","step 260 : 0.028509119525551796\n","step 270 : 0.006064563058316708\n","step 280 : 0.005579332821071148\n","step 290 : 0.006157734896987677\n","step 300 : 0.004537112545222044\n"]}]},{"cell_type":"markdown","source":["### Inference\n","With the results trained in the previous process, select one of the data and test it. Since this article is one sentence, let's try it with the input sentence."],"metadata":{"id":"AnGFtqvA9N0C"}},{"cell_type":"code","source":["result = []\n","result_ids = []\n","model.eval()\n","with torch.no_grad():\n","    predictions = model(tensors_src)\n","\n","    start = len(tokenizer.tokenize(input_text))\n","    count = 0\n","    while start < len(predictions[0]):\n","        predicted_index = torch.argmax(predictions[0,start]).item()\n","        \n","        predicted_token = tokenizer.convert_ids_to_tokens([predicted_index])\n","        if '[SEP]' in predicted_token:\n","            break\n","        if count == 0:\n","            result = predicted_token\n","            result_ids = [predicted_index]\n","        else:\n","            result+= predicted_token\n","            result_ids+= [predicted_index]\n","\n","        count += 1\n","        start += 1\n","        \n","print(\"tokenized target :\", tokenized_trg_text)\n","print(\"result_ids       :\",result_ids)\n","print(\"result           :\",result)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Dtv74cIAn-Rm","executionInfo":{"status":"ok","timestamp":1643529111699,"user_tz":-540,"elapsed":6,"user":{"displayName":"Richard Minsoo Go","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"09628967547080180869"}},"outputId":"38dbbcd3-9344-4e00-a101-f26bb3f745a9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tokenized target : ['je', 've', '##ux', 'ache', '##ter', 'le', 'nouveau', 'mac', '##book', 'pro', 'apple', 'm1', 'pro']\n","result_ids       : [15333, 2310, 5602, 12336, 3334, 3393, 25272, 6097, 8654, 4013, 6207, 23290, 4013]\n","result           : ['je', 've', '##ux', 'ache', '##ter', 'le', 'nouveau', 'mac', '##book', 'pro', 'apple', 'm1', 'pro']\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"51_2_Torch_Pretrained_BERT_NMT_BERT_Tokenizer","provenance":[],"authorship_tag":"ABX9TyPnbSEFlYUbYG1J8OvsKwzH"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}